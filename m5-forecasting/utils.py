"""Copyright 2020 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    https://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
"""
import numpy as np
import pandas as pd
from sklearn.preprocessing import OrdinalEncoder


def downcast(df):
    # Downcast in order to save memory
    cols = df.dtypes.index.tolist()
    types = df.dtypes.values.tolist()
    for i, t in enumerate(types):
        if "int" in str(t):
            if (
                df[cols[i]].min() > np.iinfo(np.int8).min
                and df[cols[i]].max() < np.iinfo(np.int8).max
            ):
                df[cols[i]] = df[cols[i]].astype(np.int8)
            elif (
                df[cols[i]].min() > np.iinfo(np.int16).min
                and df[cols[i]].max() < np.iinfo(np.int16).max
            ):
                df[cols[i]] = df[cols[i]].astype(np.int16)
            elif (
                df[cols[i]].min() > np.iinfo(np.int32).min
                and df[cols[i]].max() < np.iinfo(np.int32).max
            ):
                df[cols[i]] = df[cols[i]].astype(np.int32)
            else:
                df[cols[i]] = df[cols[i]].astype(np.int64)
        elif "float" in str(t):
            if (
                df[cols[i]].min() > np.finfo(np.float16).min
                and df[cols[i]].max() < np.finfo(np.float16).max
            ):
                df[cols[i]] = df[cols[i]].astype(np.float16)
            elif (
                df[cols[i]].min() > np.finfo(np.float32).min
                and df[cols[i]].max() < np.finfo(np.float32).max
            ):
                df[cols[i]] = df[cols[i]].astype(np.float32)
            else:
                df[cols[i]] = df[cols[i]].astype(np.float64)
        elif t == np.object:
            if cols[i] == "date":
                df[cols[i]] = pd.to_datetime(df[cols[i]], format="%Y-%m-%d")
            else:
                df[cols[i]] = df[cols[i]].astype("category")
    return df


def reduce_mem_usage(df, verbose=True):
    numerics = ["int16", "int32", "int64", "float16", "float32", "float64"]
    start_mem = df.memory_usage().sum() / 1024 ** 2
    for col in df.columns:
        col_type = df[col].dtypes
        if col_type in numerics:
            c_min = df[col].min()
            c_max = df[col].max()
            if str(col_type)[:3] == "int":
                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                    df[col] = df[col].astype(np.int8)
                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                    df[col] = df[col].astype(np.int16)
                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                    df[col] = df[col].astype(np.int32)
                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:
                    df[col] = df[col].astype(np.int64)
            else:
                if (
                    c_min > np.finfo(np.float16).min
                    and c_max < np.finfo(np.float16).max
                ):
                    df[col] = df[col].astype(np.float16)
                elif (
                    c_min > np.finfo(np.float32).min
                    and c_max < np.finfo(np.float32).max
                ):
                    df[col] = df[col].astype(np.float32)
                else:
                    df[col] = df[col].astype(np.float64)
    end_mem = df.memory_usage().sum() / 1024 ** 2
    if verbose:
        print(
            "Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)".format(
                end_mem, 100 * (start_mem - end_mem) / start_mem
            )
        )
    return df


def categorize_calendar(df):
    df = df.drop(["date", "weekday"], axis=1)
    df = df.assign(d=df.d.str[2:].astype(int))
    df = df.fillna("missing")
    cols = list(set(df.columns) - {"wm_yr_wk", "d"})
    df[cols] = OrdinalEncoder(dtype="int").fit_transform(df[cols])
    df = reduce_mem_usage(df)
    return df


def prep_selling_prices(df):
    gr = df.groupby(["store_id", "item_id"])["sell_price"]
    df["diff_week_price"] = gr.diff().fillna(0)
    df["sell_price_rel_diff"] = gr.pct_change()
    df["sell_price_roll_sd7"] = gr.transform(lambda x: x.rolling(7).std())
    df["sell_price_cumrel"] = (gr.shift(0) - gr.cummin()) / (
        1 + gr.cummax() - gr.cummin()
    )
    df = reduce_mem_usage(df)
    return df


def reshape_sales(df, drop_d=None):
    if drop_d is not None:
        df = df.drop(["d_" + str(i + 1) for i in range(drop_d)], axis=1)
    df = df.assign(id=df.id.str.replace("_validation", ""))
    df = df.reindex(
        columns=df.columns.tolist() + ["d_" + str(1913 + i + 1) for i in range(2 * 28)]
    )
    df = df.melt(
        id_vars=["id", "item_id", "dept_id", "cat_id", "store_id", "state_id"],
        var_name="d",
        value_name="demand",
    )
    df = df.assign(d=df.d.str[2:].astype("int16"))
    return df


def prep_sales(df):
    df["lag_t28"] = df.groupby(["id"])["demand"].transform(lambda x: x.shift(28))
    df["rolling_mean_t7"] = df.groupby(["id"])["demand"].transform(
        lambda x: x.shift(28).rolling(7).mean()
    )
    df["rolling_mean_t30"] = df.groupby(["id"])["demand"].transform(
        lambda x: x.shift(28).rolling(30).mean()
    )
    df["rolling_mean_t60"] = df.groupby(["id"])["demand"].transform(
        lambda x: x.shift(28).rolling(60).mean()
    )
    df["rolling_mean_t90"] = df.groupby(["id"])["demand"].transform(
        lambda x: x.shift(28).rolling(90).mean()
    )
    df["rolling_mean_t180"] = df.groupby(["id"])["demand"].transform(
        lambda x: x.shift(28).rolling(180).mean()
    )
    df["rolling_std_t7"] = df.groupby(["id"])["demand"].transform(
        lambda x: x.shift(28).rolling(7).std()
    )
    df["rolling_std_t30"] = df.groupby(["id"])["demand"].transform(
        lambda x: x.shift(28).rolling(30).std()
    )

    # Remove rows with NAs except for submission rows. rolling_mean_t180 was selected as it produces most missings
    df = df[(df.d >= 1914) | (pd.notna(df.rolling_mean_t180))]
    df = reduce_mem_usage(df)

    return df


def make_X(df, dense_cols, cat_cols):
    # Input dict for training with a dense array and separate inputs for each embedding input
    X = {"dense1": df[dense_cols].to_numpy()}
    for i, v in enumerate(cat_cols):
        X[v] = df[[v]].to_numpy()
    return X


def day_from_date(date, cal):
    filtered = cal[cal["date"] == date]
    if len(filtered):
        return filtered["weekday"].item()
    else:
        raise ValueError("date {} is not in calendar".format(date))


def d_from_date(date, cal):
    filtered = cal[cal["date"] == date]
    if len(filtered):
        return filtered["d"].item()
    else:
        raise ValueError("date {} is not in calendar".format(date))


def date_from_d(d, cal):
    filtered = cal[cal["d"] == d]
    if len(filtered):
        return filtered["date"].item()
    else:
        raise ValueError("d {} is not in calendar".format(d))


def merge_with_calendar(sales, cal, item_id, d_cols):
    example = sales.loc[sales["id"] == item_id][d_cols].T

    col_name = example.columns.item()
    if item_id.split("_")[-1] == "validation" or item_id.split("_")[-1] == "evaluation":
        item_id = "_".join(item_id.split("_")[:-1])
    example = example.rename(columns={col_name: item_id})  # Name it correctly
    example = example.reset_index().rename(columns={"index": "d"})  # make the index "d"
    example = example.merge(cal, how="left", validate="1:1")

    return example
